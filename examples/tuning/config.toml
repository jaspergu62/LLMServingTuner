# -------------------------寻优相关参数配置------------------------------------------------
n_particles = 10
iters = 5
ttft_penalty = 1
tpot_penalty = 0
success_rate_penalty = 5.0
ttft_slo = 1
tpot_slo = 0.05
service = "master"
sample_size = 1000
# 自定义终止寻优条件，当相对上一轮的相对误差小于这个值时，考虑终止寻优, -inf表示，不自动终止，跑完所有迭代计划。
ftol = -inf
ftol_iter = 3 # 自定义终止条件，第几次满足相对误差的时候，进行终止。
service = "master" # 服务是双机运行时需要使用。 主节点服务配置为master，从节点服务配置为slave。
sample_size = 1000 # 对原始数据集采样大小，用采样后的数据进行调优。
mem_coefficient = 0.8 # kv 显示使用剩余显存系数，
scaling_coefficient = 1.3 # 理论推导计算出max batch size上限后，将上限缩放的比例
theory_guided_enable = true # 是否开启理论推导，来压缩部分搜索空间,使用前 请确保显存未被占用，否则会无效。

use_surrogate = true # 是否开启surrogate
[suggrogate]
objective_index = 0
initial_points = 10
strategy = "conservative"
feasibility_threshold = -1.2

[pso_options]
# 寻优算法 寻优方向和速度控制参数
c1 = 2.0 # 推荐范围 0-4, c1 c2 2, c1 1.6和c2 1.8, c1 1.6 和c2 2
c2 = 2.0
w = 1.8 # 推荐范围0.4,2， 典型取值，0.9  1.2 1.5  1.8
[pso_strategy]
# 寻优算法，各个寻优控制参数的变化策略，支持 exp_decay, nonlin_mod, lin_variation, random
w = "exp_decay"
c1 = "exp_decay"
c2 = "exp_decay"

# -------------------------CBO代理模型配置 (默认开启)------------------------------------------------
[cbo]
enabled = true              # 是否启用CBO代理模型 (设置为false可关闭)
initial_points = 5          # 启用代理模型前的真实评估次数
strategy = "conservative"   # 候选筛选策略
feasibility_threshold = -1.2  # 可行性阈值

# -------------------------选取top_k进入精调------------------------------------------------
[data_storage]
pso_top_k = 0


# -------------------------测评工具相关配置------------------------------------------------
[vllm_benchmark.command]
host = "127.0.0.1"
port = "8010"
model = "/ssd3/models/Qwen3-30B-A3B"
served_model_name = "Qwen3-30B-A3B"
dataset_name = "sharegpt"
dataset_path = "/home/airr/hyj/dataset/ShareGPT_V3_unfiltered_cleaned_split.json"
num_prompts = 1000
others = ""


value = 128


# -------------------------vllm相关配置------------------------------------------------
[vllm]
[vllm.command]
host = "127.0.0.1"
port = "8010"
model = "/ssd3/models/Qwen3-30B-A3B"
served_model_name = "Qwen3-30B-A3B"
others = ""
[[vllm.target_field]]
name = "MAX_NUM_BATCHED_TOKENS"
config_position = "env"
min = 8192
max = 65536
dtype = "int"
value = 8192
[[vllm.target_field]]
name = "MAX_NUM_SEQS"
config_position = "env"
min = 32
max = 512
dtype = "int"
value = 64
[[vllm.target_field]]
name = "CONCURRENCY" 
config_position = "env"
min = 1
max = 1000
dtype = "int"
value = 100
[[vllm.target_field]]
name = "REQUESTRATE" 
config_position = "env"
min = 1
max = 1000
dtype = "float"
value = 100

# ----------------------latency model相关配置------------------------------------------------
[latency_model]
model_path = "/tmp/latency_model/model/xgb_model.ubj"

# -------------------------kubectl相关配置------------------------------------------------
[kubectl]
kubectl_default_path = ""